# Integrating Symbolic, Structural, and Semantic Embeddings in Limnos

## Introduction  

**Limnos** is a testing framework for code intelligence that unifies two retrieval-augmented generation approaches – **PathRAG** and **GraphRAG** – on a single ArangoDB-hosted code graph. The graph encodes code relationships (imports, function calls, class hierarchies, etc.) as nodes and edges. Currently, Limnos leverages **XnX notation** for symbolic graph traversal queries, providing *symbolic awareness* of code relationships. To push the limits of deep code understanding, we propose integrating two additional modalities into Limnos: **ISNE** (self-supervised Inductive Shallow Neighborhood Embeddings) for *structural awareness* of the graph topology, and a **BERT-based model** (such as CodeBERT/GraphCodeBERT) for *semantic content awareness*. This report examines the feasibility of this three-pronged embedding strategy, outlines an implementation plan, identifies required tools, discusses potential bottlenecks, and compares related work.

## Feasibility and Synergy Analysis  

Combining symbolic, structural, and semantic representations is technically feasible and potentially highly synergistic for code intelligence:

- **Symbolic Awareness (XnX Graph Paths):** XnX notation provides a formal syntax to traverse code relationships with weights, directionality, and temporal constraints ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=relationships%20across%20disciplines,XnX%20structure)). In Limnos, XnX-powered queries on the ArangoDB graph yield precise, interpretable relationships – e.g. finding the exact call chain between two functions or all imports of a module. This ensures high precision and interpretability (we know *exactly* why a code item is retrieved).

- **Structural Awareness (Graph Topology via ISNE):** ISNE embeddings capture each node’s position and neighborhood structure in the code graph. Unlike symbolic queries that return explicitly linked nodes, structural embeddings place *topologically similar* nodes near each other in vector space, even if they are not directly connected by an edge. For example, two functions in different modules that call similar APIs might end up with similar structural embeddings, indicating analogous roles in the codebase. ISNE’s inductive, self-supervised approach generalizes to new nodes and emphasizes local neighborhoods ([ISNE Explained | Papers With Code](https://paperswithcode.com/method/isne#:~:text=Inductive%20Shallow%20Node%20Embedding%20extends,over%20traditional%20shallow%20embedding%20methods)). This adds a *broader context* – nodes that “play similar structural roles” can be suggested by similarity search, complementing direct neighbors. Prior work suggests such structural representations are robust and outperform traditional shallow embeddings in capturing graph context ([ISNE Explained | Papers With Code](https://paperswithcode.com/method/isne#:~:text=neighborhood%20structure%20of%20each%20node%2C,networks%2C%20consistently%20achieving%20over%2090)).

- **Semantic Awareness (BERT-Based Content Embeddings):** A modern transformer-based model (e.g. **CodeBERT** or **GraphCodeBERT**) can embed the actual content of code (source text, docstrings, identifiers) into a vector space reflecting functional semantics. This allows *content-based similarity*: functions implementing similar logic or having related purpose will be close, even if structurally far apart. For instance, a “parseJSON” function and a “parseXML” function may not call each other or share neighbors, but semantic embeddings can recognize both are parsing routines. Using a BERT-family model fine-tuned for code, like **GraphCodeBERT** which incorporates code structure (data flow) into its representations, has proven effective: GraphCodeBERT achieved state-of-the-art on code search and clone detection tasks by leveraging both code tokens and structural edges ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=the%20task%20of%20masked%20language,level%20attentions%20over)). This indicates semantic vectors can significantly enhance code retrieval beyond syntax matching.

**Synergy:** These three modalities cover complementary facets of “relatedness.” Symbolic XnX traversal provides exact relational chains (great for precision and factual correctness). Structural ISNE vectors cluster code by usage patterns or architecture (capturing analogies and high-level structural context). Semantic BERT vectors capture the meaning in code or documentation (handling naming differences and natural language queries). Using them together can mitigate each other’s weaknesses. Notably, recent research on **HybridRAG** – which combines knowledge graph retrieval (GraphRAG) with vector-based retrieval – found that the hybrid approach outperforms using either graphs or vectors alone in complex domains ([[2408.04948] HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction](https://arxiv.org/abs/2408.04948#:~:text=techniques%20,The%20proposed%20technique%20has)) ([Some Perspectives on HybridRAG in an ArangoDB World](https://arangodb.com/2024/10/some-perspectives-on-hybridrag-in-an-arangodb-world/#:~:text=The%20study%20shows%20that%20a,in%20some%20cases%20be%20sufficient)). In other words, graph + embeddings together yield more *relevant and comprehensive* results than either method independently. Likewise for code, GraphCodeBERT’s success shows that injecting structural signals into semantic models improves performance ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=empirical%20improvements%20on%20a%20variety,and%20does%20not%20bring%20an)) ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=the%20task%20of%20masked%20language,level%20attentions%20over)). All these point to a strong theoretical foundation that symbolic, structural, and semantic components will reinforce each other rather than conflict.

From a technical standpoint, ArangoDB’s latest capabilities make this integration viable. ArangoDB is a **multi-model database**, and recent versions (Developer Preview as of late 2024) integrate Facebook’s **FAISS** library to support vector embeddings as a first-class index in ArangoDB’s AQL query language ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=Vector%20search%20is%20gaining%20traction,production%20release%20in%20Q1%2C%202025)). This means Limnos’s ArangoDB graph can store embedding vectors for each code node and perform efficient similarity searches directly via AQL (e.g. using `APPROX_NEAR_COSINE` for KNN search on embeddings ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=Now%2C%20let%E2%80%99s%20query%20the%20items,0.1%2C%200.3%2C%200.5%2C%20%E2%80%A6))). Furthermore, ArangoDB’s multi-model nature allows combining graph traversal and vector search in one query. Indeed, Arango’s documentation demonstrates workflows that *“combine vector search with graph traversal for advanced use cases,”* even integrating results in GraphRAG pipelines ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=library%2C%20ArangoDB%20brings%20scalable%2C%20high,production%20release%20in%20Q1%2C%202025)). Therefore, the unified ArangoDB backend of Limnos is well-suited to host all three modalities and let us query them together.

In summary, integrating XnX, ISNE, and BERT embeddings in Limnos is not only feasible but likely to be effective. The expected outcome is **deep code intelligence** – the system becomes aware of exact symbolic relations, broader structural context, and semantic meaning simultaneously. This should improve retrieval precision (by following true code links), recall (by also surfacing analogous or semantically similar code that isn’t directly linked), and ultimately the quality of PathRAG/GraphRAG’s generated answers. The key challenge is orchestrating these elements, which we address next in an implementation plan.

## Implementation Plan  

To integrate ISNE structural embeddings and BERT-based content embeddings into Limnos (alongside the existing XnX/Arango graph), we propose the following step-by-step plan:

**1. Extend the Graph Schema for Embeddings:**  
Augment the ArangoDB graph schema to store two new vector attributes on each code node document:

- `struct_embed`: a vector (e.g. list of floats) representing the node’s structural embedding.
- `semantic_embed`: a vector for the node’s content semantic embedding.  
Ensure the ArangoDB version supports vector indexing. Create a **vector index** on each of these fields (or a combined one) with appropriate dimensions and similarity metric (cosine is typical for normalized embeddings) ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=,)). For example, using arangosh or ArangoDB driver:  

```js
db.codeNodes.ensureIndex({ 
  type: "vector", 
  fields: ["struct_embed"], 
  dimensions: 128, // (if using 128-dim structural embeddings)
  metric: "cosine" 
});
```  

Do similarly for `semantic_embed` with the dimension matching the BERT model (e.g. 768 for BERT-base). This index will allow efficient KNN search via AQL (Arango will utilize FAISS under the hood ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=Vector%20search%20is%20gaining%20traction,production%20release%20in%20Q1%2C%202025))).

**2. Compute ISNE Structural Embeddings:**  
Next, generate the ISNE embeddings for all nodes in the code graph. This involves:  

- **Exporting Graph Data:** Use ArangoDB’s drivers (Python driver or ArangoDB HTTP API) to extract the graph structure. For instance, retrieve all nodes and their adjacency lists (neighbors). The relationships may include different types (calls, imports, etc.), which we can initially treat as an undirected/unweighted graph for embedding purposes (or incorporate edge types if the embedding algorithm supports it).  
- **Choosing an Embedding Algorithm:** Since ISNE (Inductive Shallow Node Embedding) is a relatively new method, we can either implement it or use available reference code. The reference implementation of ISNE ([GitHub - ricsi98/inductive-shallow-node-embedding: This is the reference implementation of the Inductive Shallow Node Embedding paper.](https://github.com/ricsi98/inductive-shallow-node-embedding#:~:text=Inductive%20Shallow%20Node%20Embedding)) (by Kiss et al.) can be adapted. ISNE uses a shallow encoder that aggregates a node’s neighbor information to produce an embedding, training itself in a self-supervised manner (possibly by predicting neighbors or using negative sampling). If ISNE code is not readily plug-and-play, an alternative is to use a widely available graph embedding technique like **Node2Vec** or **GraphSAGE** in unsupervised mode (GraphSAGE can be trained to predict a node’s neighborhood features, achieving a similar effect to ISNE). The key is to ensure the method is **inductive** – after training on the existing graph, it can embed new nodes without retraining the entire model. ISNE is explicitly designed to generalize to unseen nodes by architecture ([ISNE Explained | Papers With Code](https://paperswithcode.com/method/isne#:~:text=Inductive%20Shallow%20Node%20Embedding%20extends,over%20traditional%20shallow%20embedding%20methods)), so it fits this requirement.  
- **Embedding Computation:** Using a library such as **PyTorch Geometric** or **DGL (Deep Graph Library)**, implement the chosen embedding model. For ISNE, one would define the encoder network that, for each node, aggregates neighbor information (e.g. via averaging or a small neural network) to produce the embedding. Train this model on the Limnos graph in a self-supervised way (e.g. using random walks or neighbor prediction as the learning task). Monitor training to ensure convergence and that embeddings capture meaningful structure (maybe visualize or evaluate on a known relatedness, if any).  
- **Storing Embeddings:** Once computed, write the embedding vectors back to the ArangoDB. Each node document in the `codeNodes` collection gets its `struct_embed` field set. This can be done in bulk via Arango’s batch HTTP API or in Python by iterating and updating documents. Because the vectors might be high-dimensional, ensure ArangoDB is configured for slightly larger document sizes or consider storing as lists of floats. (ArangoDB can store numeric arrays as attributes natively.)

**3. Compute Semantic Content Embeddings:**  
In parallel, generate the BERT-based content embeddings for code:  

- **Select a Pretrained Model:** For code data, a model like **CodeBERT** or **GraphCodeBERT** is ideal. CodeBERT is a transformer pre-trained on source code and natural language, and GraphCodeBERT is an advanced variant that also considers code’s data flow graph ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=regard%20a%20code%20snippet%20as,In%20addition%20to%20using)). Either can output a fixed-size vector for a code snippet. If using GraphCodeBERT, we get the benefit of some structural awareness in the embedding itself (though it’s mainly for the code’s internal structure, not the project-wide call graph). We could also consider a Sentence-BERT model fine-tuned on code search tasks for better semantic similarity.  
- **Define Node Content to Embed:** Decide what text/code represents each node for embedding. For a function node, the content could be the function’s source code (truncated if very large), or a combination of its signature and docstring, or an abstracted form (e.g. using the function name and the names of calls it makes). We should be consistent: e.g., use the function’s definition text up to a certain length. For a module node, perhaps the list of its global symbols or a summary of its contents. Because BERT models have a token limit (512 tokens for BERT-base), ensure the content fits or use truncation/summary if needed.  
- **Embedding Computation:** Use the HuggingFace Transformers library to load the chosen model. If using CodeBERT/GraphCodeBERT, these can be loaded via their model name (e.g. `microsoft/codebert-base` or `microsoft/graphcodebert-base`). Use the model in inference mode to compute embeddings: typically, take the output of the model’s `[CLS]` token or use a pooling strategy to get a single vector per input. The process can be streamlined using **sentence-transformers** library, which provides easy `.encode()` methods for getting sentence embeddings and has versions of CodeBERT.  
- **Batch Processing:** Iterate over all code nodes and compute their semantic vector. This is computationally expensive if the codebase is large, so use batching and possibly GPU acceleration. We might also reuse any cached representations if the codebase is static.  
- **Storing Embeddings:** Similar to structural, store the resulting `semantic_embed` vectors back into each node’s document in ArangoDB. With the vector indices in place, the database can now handle similarity queries on this field as well.

**4. Integrate into Query Pipeline:**  
With data preparation done, we modify the Limnos retrieval pipeline (the way queries are answered) to utilize the new embeddings in concert with XnX symbolic queries:

   1. **Query Analysis:** When a user poses a query or test (which in a code intelligence setting could be a natural language question about the code, or a search for related functions, etc.), first determine if it references specific code entities. For example, if the query is *“Find functions that directly or indirectly call **Parser.parse**”*, it contains an explicit function name. In such cases, we can directly use XnX (or a standard AQL graph traversal) to find relevant nodes (e.g. traverse the “calls” edges from `Parser.parse`). This yields an initial set of exact matches or anchor nodes.
   2. **Semantic Search for Relevant Content:** If the query is more abstract (e.g. *“How is JSON parsing implemented?”*), or as a complementary step, perform a vector search on semantic embeddings. Use the same BERT model to embed the query (for natural language, a model like CodeBERT can handle it if fine-tuned on NL-PL pairs; if not, we might need a separate embedding model for natural language vs code – however CodeBERT was trained on NL-PL parallel data, so it can map a NL description to related code). Then use an AQL query with `APPROX_NEAR_COSINE` on `semantic_embed` to retrieve top-K code nodes whose content is most semantically similar to the query vector ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=Now%2C%20let%E2%80%99s%20query%20the%20items,0.1%2C%200.3%2C%200.5%2C%20%E2%80%A6)). This will return code pieces that are likely related to the user’s intent by functionality or description (e.g. all functions whose embedding suggests they deal with JSON).  
   3. **Structural Analogy Retrieval:** For each *anchor* node that seems especially relevant (either explicitly named or found via semantic search), we leverage the structural embedding space to find analogous nodes:
      - Perform a KNN search on the `struct_embed` field with the anchor’s structural vector as the query. This yields nodes that have a similar neighborhood topology to the anchor. In practice, this might surface code in a different part of the project that has a similar pattern of connections. For example, if the anchor is a parser function in one module, this might find parser functions in other modules with similar call structures. These results can broaden the context, ensuring we don’t miss relevant code that wasn’t captured by semantic similarity (perhaps because it uses different terminology) or by direct links.
      - We may filter or post-rank these structural results by semantic relevance as well (to ensure they are not just structurally similar but functionally irrelevant). Often, however, structural similarity in a code graph correlates with similar roles, which is useful for tasks like finding analogues or potential duplicates.
   4. **Symbolic Graph Expansion:** Now take the union of nodes found through (a) direct symbolic query, (b) semantic embedding search, and (c) structural embedding search. This union (or a selection thereof) forms a set of candidate relevant code nodes. Use XnX/AQL graph traversals to **expand the local neighborhoods** of these nodes for context. For instance, fetch each node’s immediate neighbors in the graph (functions it calls or that call it, modules it belongs to, etc.), since GraphRAG typically requires the subgraph around relevant entities. Limnos can use an AQL query to get all edges among these candidate nodes ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=Once%20paths%20between%20neighborhoods%20are,local%20neighborhoods%20for%20detailed%20analysis)). The XnX notation’s features (like edge weight and temporal constraints) can guide this step – e.g. we might filter to only include edges above a certain confidence weight or within relevant time/version bounds ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=We%20define%20neighborhoods%20in%20three,complementary%20ways)). At this stage, we effectively have a **multi-modal subgraph**: it includes nodes directly asked for, nodes semantically similar to the query, and nodes structurally similar to those, plus all their interconnections from the original code graph.
   5. **Ranking and Pruning:** If the combined set of nodes is very large, apply some ranking or pruning. PathRAG’s algorithm for pruning low-relevance paths ([[2502.14902] PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths](https://arxiv.org/abs/2502.14902#:~:text=methods%20lies%20in%20the%20redundancy,available%20at%20the%20following%20link)) could be adapted: for example, PathRAG suggests using flow-based confidence scoring to remove redundant info. We can rank candidates by a combination of their semantic similarity score (from step 2) and structural scores, or by whether they were directly linked to query terms. Perhaps boost nodes that were found by multiple methods (e.g. a function that was both semantically and structurally retrieved likely is very relevant). The **Greatest Limiting Factor (GLF)** concept from XnX can also be applied to limit how much info we pass forward – for instance, set a threshold on the number of nodes or total token size of code to include ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=5.%20,path%20selection%20and%20retrieval%20quality)) ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=directionality%2C%20and%20temporal%20validity%203,wide%20limitations%20on%20path%20selection)).
   6. **PathRAG and GraphRAG Execution:** Finally, feed the curated graph data into the respective evaluation pipelines:
      - *For PathRAG:* Use the integrated graph to find key relational **paths** connecting the query-related nodes. The XnX notation (with weighted edges) helps here – we can run a path search query that finds high-confidence paths where the product of edge weights is above a threshold ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=cypher%20MATCH%20p%3D%28a%29,rel.weight%5D%20AS%20scores)). Each path is a sequence like *ModuleA ->calls-> FuncX ->calls-> FuncY*, representing a relational chain. Convert these top paths into a textual form (e.g. a formatted explanation of the relationship) to provide to the LLM, as PathRAG prescribes ([[2502.14902] PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths](https://arxiv.org/abs/2502.14902#:~:text=methods%20lies%20in%20the%20redundancy,art%20baselines%20across%20six%20datasets)).
      - *For GraphRAG:* Use the subgraph of all retrieved nodes and edges as the context for GraphRAG. This could mean performing a **message-passing neural network** over the subgraph to encode it, or simply serializing the subgraph (with all node content and links) in a structured prompt. Given the enhancements, GraphRAG can now incorporate node attributes like the embeddings or confidence weights during its neighborhood analysis ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=1.%20,edge%20attributes%20into%20the%20representation)), but even without that, it benefits from having a more targeted subgraph. GraphRAG’s step will produce the final answer or intermediate representation which the LLM uses to answer the query.

Throughout the above process, all three modalities work in concert: the symbolic step grounds the retrieval in known code links, semantic search brings in conceptually related items, and structural search finds topologically similar items. This integrated pipeline directly leverages ArangoDB’s ability to do graph traversals and vector searches together. For example, a single AQL query could potentially combine these steps, such as first using a full-text or name filter, then a vector similarity filter, then a traversal, etc. In practice, it may be easier to do it in multiple queries or in application logic for clarity and flexibility.

**5. Validation and Iteration:**  
After implementation, validate the approach using the Limnos framework’s evaluation tasks. We would compare:

- Baseline PathRAG/GraphRAG (using only the symbolic graph) vs. the enhanced system (symbolic + ISNE + BERT).
- Metrics like retrieval precision, recall, and end-to-end QA performance.
We expect to see improved recall (finding relevant code that wasn’t directly linked) without sacrificing precision. If needed, adjust weighting of modalities (e.g. if semantic retrieval returns some false positives, tighten the similarity threshold or increase reliance on structural filtering).

**6. Libraries and Tools Summary:**  
To support the above implementation, the following tools will be instrumental:

- **ArangoDB 3.12+** (with Vector Search Developer Preview/Enterprise): Core datastore for graph + vectors. Allows AQL graph traversals and `APPROX_NEAR_COSINE` queries for vector similarity ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=Now%2C%20let%E2%80%99s%20query%20the%20items,0.1%2C%200.3%2C%200.5%2C%20%E2%80%A6)).
- **ArangoDB Drivers (Python/Javascript)**: To programmatically update the graph with embeddings and execute complex queries from the application.
- **PyTorch Geometric or DGL**: For computing graph embeddings (ISNE, Node2Vec, etc.) on the extracted graph data. These frameworks provide utilities for graph neural networks and random-walk-based embeddings.
- **Hugging Face Transformers**: To load CodeBERT/GraphCodeBERT and compute content embeddings. Alternatively, **Sentence Transformers** (which internally uses HuggingFace models) for easier high-level interface.
- **ISNE Implementation**: If sticking closely to the ISNE method, use the reference code provided by the authors ([GitHub - ricsi98/inductive-shallow-node-embedding: This is the reference implementation of the Inductive Shallow Node Embedding paper.](https://github.com/ricsi98/inductive-shallow-node-embedding#:~:text=Inductive%20Shallow%20Node%20Embedding)) or implement from the description. Ensure the model is saved so that we can reuse it for future incremental embeddings (ISNE’s inductive nature means we can embed a new node using the trained encoder without retraining on entire graph).
- **LangChain or LlamaIndex (optional)**: These higher-level frameworks can orchestrate hybrid graph+vector queries. As Arango’s example notes, LangChain can integrate vector search and GraphRAG in natural language query workflows ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=This%20guide%20will%20walk%20you,integrate%20Vector%20Search%20and%20GraphRAG)). This could simplify query parsing and execution in the application layer of Limnos, although it’s not strictly necessary if we handle it manually.

By following this plan, we incrementally layer structural and semantic knowledge onto Limnos’s existing capabilities. Each step should be tested – for example, after step 2, verify via nearest-neighbor queries that structurally similar nodes (according to ISNE) make intuitive sense; after step 3, verify that semantically similar code is retrieved as expected (perhaps compare to simple keyword search results to see the added value). Once the pipeline is functional, we can proceed to analyzing performance and potential issues as discussed next.

## Potential Challenges and Bottlenecks  

Integrating three different modalities inevitably introduces complexity. We address potential bottlenecks and challenges below:

- **Computational Overhead:** Computing and using embeddings will incur additional runtime and storage costs. The initial embedding computations (ISNE training and BERT inference on code) are expensive but can be done offline. The online query pipeline adds steps for embedding-based retrieval, but these can be optimized. Vector search in ArangoDB is backed by FAISS and is designed to be high-performance ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=Vector%20search%20is%20gaining%20traction,production%20release%20in%20Q1%2C%202025)), but KNN searches are still O(n) per query in the worst case (mitigated by approximate indexing). If the code graph has, say, tens of thousands of nodes, retrieving top-10 neighbors via approximate cosine similarity should be very fast. A bigger concern is the LLM’s context length: combining results from symbolic, structural, and semantic sources means we might feed more code into the final prompt. We must carefully prune as noted to avoid hitting context size limits or increasing generation latency. The **GLF (Greatest Limiting Factor)** mechanism from XnX can dynamically limit how many edges or paths are considered based on resource constraints ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=5.%20,path%20selection%20and%20retrieval%20quality)). We may implement GLF as a heuristic that if the intermediate result set exceeds X nodes, we trim those with lowest combined relevance score.

- **Storage and Indexing:** Storing two embedding vectors per node (possibly 128-dim for struct and 768-dim for semantic) will increase the database size. With thousands of nodes this is negligible, but with millions it could be significant. ArangoDB’s vector index also consumes memory proportional to `nLists` (the clustering parameter for FAISS) ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=,)). We might choose a moderate dimension for structural embeddings (even 64 or 128 may suffice to capture graph structure) to save space. If memory becomes an issue, an alternative is to store the vectors outside Arango in a dedicated vector store (like Milvus, Qdrant, or FAISS on disk) and query that separately. However, this complicates the unified architecture – given Arango’s built-in support and the goal of a unified store, we prefer to keep everything in Arango unless proven problematic.

- **Graph Embedding Quality and “Resolution”:** A challenge with structural embeddings is determining the right “view” of the graph to encode. If the embedding is too *local* (e.g. only 1-hop neighbors), it might not distinguish nodes beyond their immediate connections; if too *global*, the vectors might cluster broad regions and lose nuance (or become too similar for all nodes in a large connected component). Techniques like Node2Vec let us tune the random walk length and return parameters to balance local vs. global features. ISNE’s design focuses on local neighborhoods but in an inductive way ([ISNE Explained | Papers With Code](https://paperswithcode.com/method/isne#:~:text=Inductive%20Shallow%20Node%20Embedding%20extends,over%20traditional%20shallow%20embedding%20methods)). We may need to experiment with embedding parameters: for instance, include 2-hop neighbors during training to capture slightly wider context. Additionally, the code graph is heterogeneous (different edge types: calls, imports, etc.). A single embedding might mix these or emphasize the most frequent relation. If certain relations are crucial (e.g. “calls” vs “belongs-to module”), we could weight edges or even compute separate embeddings per relation type (though combining them would be nontrivial). In practice, starting with an unweighted homogeneous approach and seeing if it yields useful similarity (like grouping by functionality) is a good first step. The fact that GraphCodeBERT found value in using a code graph (data flow) for better embeddings ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=taking%20syntactic,We%20implement%20the)) suggests that even partial structural info can improve semantic understanding.

- **Integration Complexity:** Orchestrating the three modalities requires careful pipeline design as described. There is a risk of *overwhelming* the system with too much data or conflicting signals:
  - For example, semantic search might retrieve a function that is conceptually related to the query but located in a very different part of the graph, potentially introducing irrelevant neighbors when the graph is expanded. We mitigate this by cross-checking results: if a semantically retrieved node has no path or connection at all to any other relevant nodes, we might treat it as lower priority unless the query is purely conceptual. Conversely, structural analogs might all be very similar to each other and add redundancy. Our ranking/pruning step should downweight nodes that don’t contribute new information. Essentially, we’ll likely develop a **scoring function** that combines: `score(node) = w1*semantic_sim(query, node) + w2*max_semantic_sim(node, anchors) + w3*struct_sim(node, anchors)`. The anchors here could be the core items from symbolic retrieval or query mention. Tuning these weights is a challenge but can be guided by validation on known queries.
  - Another integration hurdle is how to feed this into the LLM effectively. PathRAG suggests converting paths to textual form, which works for a handful of paths ([[2502.14902] PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths](https://arxiv.org/abs/2502.14902#:~:text=retrieved%20information%20within%20the%20prompts%2C,available%20at%20the%20following%20link)). GraphRAG might input the entire neighborhood. If we retrieve many nodes, simply concatenating code snippets can confuse the LLM. We might need to format the input in a structured way (e.g. “**Relevant Functions:** A (calls B, C); B (defined in module X); C (similar structure to A)… etc.”). Designing prompt templates that accommodate multi-modal context is part of the integration complexity, albeit outside the core retrieval logic.

- **Runtime of Graph Algorithms:** If we incorporate an on-the-fly Graph Neural Network (GNN) in GraphRAG’s step (for example, doing message passing on the neighborhood subgraph ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=Within%20each%20identified%20neighborhood%2C%20GraphRAG,performs))), that adds computational load at query time. GraphRAG could alternatively use a simpler heuristic (like just include all neighbor content). Since Limnos is a testing framework, perhaps efficiency is not paramount, but in a real deployment one would profile whether the added GNN or embedding computations are acceptable. Caching can help: frequently asked queries or their resulting subgraphs can be cached to skip recomputation. Inductive embeddings mean even if the graph updates, we can update affected node embeddings without retraining everything, which is a plus for maintainability.

- **Cold Start and Model Maintenance:** Introducing ML models (ISNE and BERT) means Limnos inherits typical ML maintenance issues. If the codebase evolves significantly, the structural embedding model might need retraining to capture new patterns (though inductive nature reduces this need). The semantic model might need fine-tuning if the code or query domain is very different from what CodeBERT was trained on. These are manageable but worth noting – e.g. we could fine-tune CodeBERT on the project’s own documentation or Q&A if available, to specialize its embeddings. This is more of an enhancement than a bottleneck, but it adds to the project scope if pursued.

In summary, while there are many moving parts, none of the challenges are show-stoppers. Modern databases and ML frameworks are capable of handling this kind of hybrid pipeline. By anticipating these bottlenecks – optimizing queries, tuning embedding parameters, and carefully merging results – we can ensure the integrated system remains efficient and yields high-quality results. The payoff is a rich retrieval system that leverages the *“best of both worlds”* from symbolic graphs and vector semantics, echoing findings from HybridRAG research that combining them yields more nuanced results ([Some Perspectives on HybridRAG in an ArangoDB World](https://arangodb.com/2024/10/some-perspectives-on-hybridrag-in-an-arangodb-world/#:~:text=The%20study%20shows%20that%20a,in%20some%20cases%20be%20sufficient)) ([[2408.04948] HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction](https://arxiv.org/abs/2408.04948#:~:text=techniques%20,The%20proposed%20technique%20has)).

## Related Work and References  

Combining graph-based and embedding-based techniques for information retrieval and reasoning is a cutting-edge approach that has parallels in recent research:

- **HybridRAG (2024):** As discussed, Bhaskarjit et al. introduced HybridRAG which fuses Knowledge Graph-based RAG (GraphRAG) with vector-based RAG ([[2408.04948] HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction](https://arxiv.org/abs/2408.04948#:~:text=complex%20formats%20of%20the%20documents,traditional%20VectorRAG%20and%20GraphRAG%20individually)). In their financial QA domain, GraphRAG alone had high precision but missed some relevant info (lower recall), whereas vector RAG had higher recall but could introduce noise. The hybrid system outperformed both, validating that a graph + vector approach can be *synergistic* ([[2408.04948] HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction](https://arxiv.org/abs/2408.04948#:~:text=techniques%20,The%20proposed%20technique%20has)). Our integration in Limnos is a similar philosophy, though specialized for code: XnX (symbolic) + ISNE (structural) + BERT (semantic) corresponds to a hybrid of structured and unstructured retrieval. The success of HybridRAG motivates our design. ArangoDB’s own evaluation also noted the promise of such combinations for complex domains ([Some Perspectives on HybridRAG in an ArangoDB World](https://arangodb.com/2024/10/some-perspectives-on-hybridrag-in-an-arangodb-world/#:~:text=The%20study%20shows%20that%20a,in%20some%20cases%20be%20sufficient)).

- **GraphCodeBERT (2021):** Daya Guo et al. developed GraphCodeBERT, a pre-trained model for code that incorporates code’s **data flow graph** into the learning process ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=code%20understanding%20process,and%20the%20other%20is%20to)). They introduced structure-aware pre-training tasks (edge prediction and alignment between code and graph) and achieved state-of-the-art results on code search and clone detection ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=the%20task%20of%20masked%20language,level%20attentions%20over)). This work is an existence proof that *structural* information (even relatively simple graph like data flow) plus *semantic* modeling improves code understanding. In our context, we are not training a single model to fuse these modalities, but we are effectively doing a late fusion by retrieving with both. We can reference GraphCodeBERT as inspiration that structural context is valuable for code intelligence – indeed, it showed the model paid more attention to structure for code search tasks ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=incorporate%20the%20code%20structure,level%20attentions%20over)). One might consider in the future an end-to-end model that directly combines our three modalities, but that would require significant model training. Our approach instead uses the graph and vectors in a modular way that can be tuned and understood independently.

- **Other Code Intelligence Systems:** There have been various attempts to improve code search and analysis by using graph-based representations:
  - **Code2Vec/Code2Seq (2019):** which use abstract syntax tree (AST) paths to represent code for tasks like method naming. These are early examples of structural code embeddings (though focused on AST paths rather than call graphs).
  - **Program Graphs in ML for Code:** Some tools build program graphs (with nodes as statements or variables) and apply GNNs for bug detection, program repair, etc. While not directly RAG systems, they show that combining code graphs with learned embeddings yields good results.
  - **KGLM / K-BERT (2020):** In NLP, methods like K-BERT inject triples from knowledge graphs into the input of BERT to ground it with symbolic knowledge. Similarly, **GreaseLM (2022)** combined a GNN over a knowledge graph with a language model, exchanging information between them for QA tasks. These illustrate *neuro-symbolic* techniques, analogous to what we attempt (though our combination is at retrieval time rather than within the model). They’ve demonstrated improved reasoning and answer accuracy by providing both neural and symbolic views of data.

- **XnX Notation Framework:** The Limnos project builds on the XnX framework, which formalizes graph relationships with weights and temporal spans. The XnX documentation itself hints at multi-faceted neighborhood definitions – *“Semantic Neighborhoods: Nodes sharing semantic properties, determined through embedding similarity or shared attributes.”* ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=We%20define%20neighborhoods%20in%20three,complementary%20ways)). Our plan essentially implements this vision: using embedding similarity to identify a semantic neighborhood in addition to the structural neighborhood (k-hop). By doing so, we follow the suggested direction in the framework to enrich what “neighborhood” means beyond just direct links. This report’s integration can be seen as an extension of XnX’s principles, adding concrete embedding techniques to realize those semantic and structural neighborhood concepts.

- **PathRAG and GraphRAG Papers:** PathRAG ([[2502.14902] PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths](https://arxiv.org/abs/2502.14902#:~:text=methods%20lies%20in%20the%20redundancy,available%20at%20the%20following%20link)) and GraphRAG are the algorithms Limnos is testing. PathRAG’s introduction of extracting minimal relational paths addresses the graph-based retrieval redundancy problem, and GraphRAG integrates graph context into generation. While these works themselves didn’t combine external embeddings, our integration provides a testing ground to see if their performance can be further boosted. For example, PathRAG could benefit from starting its path search on a better set of candidate nodes obtained via embeddings (reducing the chance of missing the optimal path that involves a semantically relevant node). GraphRAG could benefit from having a more complete subgraph (in terms of relevant nodes included), assembled by the hybrid retrieval.

In conclusion, our integration strategy aligns with and builds upon prior findings that **hybrid approaches are superior** for complex retrieval tasks. By citing these references and leveraging existing methods (ISNE for graph embeddings ([ISNE Explained | Papers With Code](https://paperswithcode.com/method/isne#:~:text=Inductive%20Shallow%20Node%20Embedding%20extends,over%20traditional%20shallow%20embedding%20methods)), advanced code models like GraphCodeBERT ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=the%20task%20of%20masked%20language,level%20attentions%20over)), and ArangoDB’s hybrid query capabilities ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=library%2C%20ArangoDB%20brings%20scalable%2C%20high,production%20release%20in%20Q1%2C%202025))), we ensure that the design of Limnos’s extension is grounded in state-of-the-art research and technology.

## Conclusion  

Integrating XnX notation, ISNE structural embeddings, and BERT-based semantic embeddings in the Limnos framework is a promising path toward enhanced code intelligence. The approach is technically sound – supported by ArangoDB’s multi-model query engine and contemporary ML models – and each modality complements the others: **symbolic** queries provide precise relations and trustworthiness, **structural** embeddings contribute a sense of graph-contextual similarity, and **semantic** embeddings bring understanding of code meaning. The implementation will involve augmenting the data layer with new vector representations and carefully orchestrating query logic to fuse results. Challenges such as increased computational load and result blending can be managed with prudent design (e.g. indexing, caching, and result scoring strategies).

If successful, this three-part strategy will allow Limnos to evaluate PathRAG and GraphRAG on a richer playing field. We anticipate more relevant code context being retrieved for a given query, leading to higher quality answers from the RAG system. In essence, the system will not only follow the known links in the code graph but also *“read between the lines”* of the graph – noticing nodes that **should** be related based on structure or semantics even if not directly linked. This mirrors how a human developer might investigate a codebase: by checking direct references, looking at similar modules, and searching by keywords or functionality. By unifying these approaches, Limnos could set a new benchmark for deep code understanding in retrieval-augmented generation systems.

**References:** The following sources informed this analysis and provide additional context: PathRAG’s approach to pruning graph retrieval ([[2502.14902] PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths](https://arxiv.org/abs/2502.14902#:~:text=methods%20lies%20in%20the%20redundancy,available%20at%20the%20following%20link)), the XnX integration framework ([XnX- Notation.md](file://file-3uzwe5ad6MpQ9P8fxTbLwB#:~:text=We%20define%20neighborhoods%20in%20three,complementary%20ways)), ArangoDB’s vector search capabilities ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=Vector%20search%20is%20gaining%20traction,production%20release%20in%20Q1%2C%202025)) ([Vector Search in ArangoDB: Insights & Hands-on Examples](https://arangodb.com/2024/11/vector-search-in-arangodb-practical-insights-and-hands-on-examples/#:~:text=This%20guide%20will%20walk%20you,integrate%20Vector%20Search%20and%20GraphRAG)), the HybridRAG study demonstrating graph+vector advantages ([[2408.04948] HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction](https://arxiv.org/abs/2408.04948#:~:text=techniques%20,The%20proposed%20technique%20has)), the ISNE method for inductive graph embeddings ([ISNE Explained | Papers With Code](https://paperswithcode.com/method/isne#:~:text=Inductive%20Shallow%20Node%20Embedding%20extends,over%20traditional%20shallow%20embedding%20methods)), and GraphCodeBERT’s success with combining code semantics and structure ([[2009.08366] GraphCodeBERT: Pre-training Code Representations with Data Flow](https://arxiv.org/abs/2009.08366#:~:text=the%20task%20of%20masked%20language,level%20attentions%20over)). These works collectively validate the feasibility and expected effectiveness of the proposed integration.
